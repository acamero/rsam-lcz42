{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48889e37-f17e-4a94-90ab-529633c79305",
   "metadata": {},
   "source": [
    "# Remote Sensing Advanced Methods - 2021\n",
    "\n",
    "\n",
    "## So2Sat LCZ42\n",
    "\n",
    "By 2050, Berlin summers could be as hot as in Canberra, Australia. Pankow, a district in the city’s north, has already declared a climate emergency in 2019 and is planning ahead. It is planting trees from the Mediterranean that can withstand the heat, and has calculated computer simulations for sunshine and cold air corridors for the construction of 1200 new apartments. A few changes, like swapping asphalt and concrete that store heat against greenery that soaks up water and provides shade, can make a difference on the local scale. Many of these changes on a local scale then make a difference on the bigger scale.\n",
    "\n",
    "To understand local climate in cities, scientists have developed the Local Climate Zone classification scheme, as part of the So2Sat project. The aim is to create a 4D urban map of the world.\n",
    "\n",
    "It differentiates between 17 zones based mainly on surface structures (such as building and tree density) as well as surface cover (green, pervious soils versus impervious grey surfaces). There are algorithms that calculate these maps from freely available satellite imagery, but there’s still room for improvement by adapting or developing suitable and advanced Convolutional Neural Network (CNN) architectures that generalise well.\n",
    "\n",
    "The outcome of So2Sat will be the first and unique global and consistent spatial data set on urban morphology (3D/4D) of settlements, and a multidisciplinary application derivate assessing population density. This is seen as a giant leap for urban geography research as well as for formation of opinions for stakeholders based on resilient data.\n",
    "\n",
    "```\n",
    "@article{zhu2020so2sat,\n",
    "  title={So2Sat LCZ42: a benchmark data set for the classification of global local climate zones [Software and Data Sets]},\n",
    "  author={Zhu, Xiao Xiang and Hu, Jingliang and Qiu, Chunping and Shi, Yilei and Kang, Jian and Mou, Lichao and Bagheri, Hossein and Haberle, Matthias and Hua, Yuansheng and Huang, Rong and others},\n",
    "  journal={IEEE Geoscience and Remote Sensing Magazine},\n",
    "  volume={8},\n",
    "  number={3},\n",
    "  pages={76--89},\n",
    "  year={2020},\n",
    "  publisher={IEEE}\n",
    "}\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a118397-9181-46aa-a443-215642d639d7",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. [Meet the Data](#1.-Meet-the-Data)\n",
    "2. [*Classical* Machine Learning: Random Forest Classifier](#2.-Classical-Machine-Learning:-Random-Forest-Classifier)\n",
    "3. [Deep Learning](#3.-Deep-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f675649-6b34-4196-9e87-99e31ff3f69b",
   "metadata": {},
   "source": [
    "## 1. Meet the Data\n",
    "\n",
    "The *So2Sat LCZ42* data set is an *Earth observation* image classification data set. It contains co-registered image patches from Sentinel-1 (10 multi-spectral bands) and Sentinel-2 (8 bands) satellite sensors, all assigned to one of the 17 *local climate zones* (LCZ) classes.\n",
    "\n",
    "The LCZ classes are as follows: \n",
    "1) compact high-rise, \n",
    "2) compact mid-rise, \n",
    "3) compact low-rise,\n",
    "4) open high-rise,\n",
    "5) open mid-rise,\n",
    "6) open low-rise,\n",
    "7) lightweight low-rise,\n",
    "8) large low-rise,\n",
    "9) sparsely built, \n",
    "10) heavy industry,\n",
    "11) dense trees,\n",
    "12) scattered tree, bush, scrub,\n",
    "14) low plants,\n",
    "15) bare rock or paved,\n",
    "16) bare soil or sand, and \n",
    "17) water (17) \n",
    "\n",
    "The data set is split into training (352,366 images), validation (24,188) and test (24,119).\n",
    "\n",
    "It is important to note that two various pools of cities were used to build So2Sat LCZ42. 32 cities around the globe were selected to form the training set, while samples from 10 different cites were used for the validation and test set, with a geographical split (east and west)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558f1ff-d24e-4dba-8a0b-8cbbfd4db827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f60af4-aa5a-4380-acad-7c13f00b83fc",
   "metadata": {},
   "source": [
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ea7c9-c9e8-4243-89f2-d2e6ac6db665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d8693-4d5c-4b16-b67f-92929ebed9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should match the name of the downloaded data set\n",
    "filename = 'data/subset_lcz42.h5'\n",
    "\n",
    "dataset = h5py.File(filename, 'r')\n",
    "\n",
    "# show the content names\n",
    "print(list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c5b1b-8f81-4a41-8457-0d1605791835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the labels\n",
    "labels = np.array(dataset['label'])\n",
    "\n",
    "# show the shape\n",
    "print(\"Labels shape: \" + str(labels.shape))\n",
    "\n",
    "# print the labels\n",
    "print(labels[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cda482-7875-4c02-8494-ce7fe7103227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Sentinel-1 data\n",
    "sen1 = np.array(dataset['sen1'])\n",
    "\n",
    "print(\"Sentinel-1 shape: \" + str(sen1.shape))\n",
    "\n",
    "def false_color(X):\n",
    "    \"\"\" False color visualization\n",
    "    \n",
    "    Sentinel-1 data in So2Sat LCZ42\n",
    "        1) the real part of the unfiltered VH channel\n",
    "        2) the imaginary part of the unfiltered VH channel\n",
    "        3) the real part of the unfiltered VV channel\n",
    "        4) the imaginary part of the unfiltered VV channel\n",
    "        5) the intensity of the refined LEE filtered VH channel\n",
    "        6) the intensity of the refined LEE filtered VV channel\n",
    "        7) the real part of the refined LEE filtered covariance matrix off-diagonal element\n",
    "        8) the imaginary part of the refined LEE filtered covariance matrix off-diagonal element\n",
    "    \"\"\"\n",
    "    band1 = X[:,:,0]\n",
    "    band2 = X[:,:,2]\n",
    "    band3 = X[:,:,2]\n",
    "\n",
    "    band1 = band1 / (band1.max()/255.0)\n",
    "    band2 = band2 / (band2.max()/255.0)\n",
    "    band3 = band3 / (band3.max()/255.0)\n",
    "\n",
    "    tc = np.dstack((band1, band2, band3))\n",
    "    \n",
    "    return tc.astype('uint8')\n",
    "\n",
    "# show one patch\n",
    "plt.subplot(121)\n",
    "# plt.imshow(10 * np.log10(sen1[10,:,:,0]), cmap=plt.cm.get_cmap('gray'))\n",
    "plt.imshow(false_color(sen1[10,:,:,:]))\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489bf06-d2b7-4a62-bda7-2cae938d4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Sentinel-2 data\n",
    "sen2 = np.array(dataset['sen2'])\n",
    "\n",
    "print(\"Sentinel-2 shape: \" + str(sen2.shape))\n",
    "\n",
    "def true_color(X):\n",
    "    \"\"\" Define True Color Sentinel image\n",
    "    \n",
    "    The function returns the MinMax scaled RGB bands\n",
    "    \n",
    "    Sentinel-2 Bands in So2Sat LCZ 42\n",
    "        1) Band B2 (Blue), 10m GSD\n",
    "        2) Band B3 (Green), 10m GSD\n",
    "        3) Band B4 (Red), 10m GSD\n",
    "        4) Band B5, upsampled to 10m from 20m GSD\n",
    "        5) Band B6, upsampled to 10m from 20m GSD\n",
    "        6) Band B7, upsampled to 10m from 20m GSD\n",
    "        7) Band B8, 10m GSD\n",
    "        8) Band B8a, upsampled to 10m from 20m GSD\n",
    "        9) Band B11, upsampled to 10m from 20m GSD\n",
    "        10) and Band B12, upsampled to 10m from 20m GSD\n",
    "\n",
    "    Matplot convention RGB [0, 255]    \n",
    "    \"\"\"    \n",
    "    blue = X[:,:,0] / (X[:,:,0].max()/255.0)\n",
    "    green = X[:,:,1] / (X[:,:,1].max()/255.0)\n",
    "    red = X[:,:,2] / (X[:,:,2].max()/255.0)\n",
    "    \n",
    "    tc = np.dstack((red, green, blue))     \n",
    "    \n",
    "    return tc.astype('uint8')\n",
    "\n",
    "# show one patch\n",
    "plt.subplot(122)\n",
    "plt.imshow(true_color(sen2[10,:,:,0:3]))\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cd53a-2941-48c6-a3b9-b0d838b756da",
   "metadata": {},
   "source": [
    "## 2. *Classical* Machine Learning: Random Forest Classifier\n",
    "\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69ca9c-5b49-4d33-8bb0-acd930758871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random forest expects a vector of features. Therefore,\n",
    "# we concatenate all bands and pixels\n",
    "X = np.reshape(sen2, (2400, 32 * 32 * 10))\n",
    "\n",
    "print(\"Post-processed Sentinel-2 data shape: \", X_train.shape)\n",
    "\n",
    "# Let us split the data into train and test\n",
    "TRAIN_SPLIT = int(labels.shape[0] * .8)\n",
    "\n",
    "X_train = X[:TRAIN_SPLIT,:]\n",
    "X_test = X[TRAIN_SPLIT:,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1206d3-75e4-4eda-a956-3e619963e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are one hot encoded, but the random forest requires\n",
    "# the class number\n",
    "y_train = np.argmax(labels[:TRAIN_SPLIT,:], axis=1)\n",
    "y_test = np.argmax(labels[TRAIN_SPLIT:,:], axis=1)\n",
    "\n",
    "print(\"Post-processed train labels shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e04b0-16cd-4759-b243-331c75aa01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a580f-0082-4dbc-a738-34b02def1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdc6a0-d74a-487e-8910-5dd6a7d9d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf)\n",
    "plt.show()\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy Random Forest Classifier: \", acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995afa99-02f6-47f5-ab78-7ee62141a389",
   "metadata": {},
   "source": [
    "## 3. Deep Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05521b3-9a1e-4763-8633-c24414409d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = sen2[:TRAIN_SPLIT,:,:,:]\n",
    "Z_test = sen2[TRAIN_SPLIT:,:,:,:]\n",
    "\n",
    "print(\"Train shape: \", M_train.shape, y_train.shape)\n",
    "\n",
    "y_train_oh = labels[:TRAIN_SPLIT,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2eab2b-4499-412b-97e7-16f960cdcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(32, 32, 10)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(17, activation='softmax')\n",
    "])\n",
    "\n",
    "simple_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366db098-3147-460b-ae31-5f41231a5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit(Z_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8653350-daef-49b4-b989-8b185dcd6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl_p = simple_model.predict(Z_test)\n",
    "\n",
    "print(\"Prediction example: \", y_pred_dl_p[0,:], \" Class: \", np.argmax(y_pred_dl_p[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8cabf4-e6fe-4a21-9f4f-551026cc7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dl = np.argmax(y_pred_dl_p, axis=1)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_dl)\n",
    "plt.show()\n",
    "\n",
    "acc_dl = accuracy_score(y_test, y_pred_dl)\n",
    "print(\"Accuracy Simple Deep Learning model: \", acc_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ea52b-c7b8-4d32-b137-c6f1bf5ee2dd",
   "metadata": {},
   "source": [
    "Let us design a *deeper* model, based on ResNet... We will use Keras [implementation](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.pyhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py) as our basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd24a36-9488-4cae-9f27-d142349953a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(\n",
    "    input_tensor, \n",
    "    kernel_size, \n",
    "    filters, \n",
    "    stage,\n",
    "    block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    input_tensor_shortcut = input_tensor\n",
    "    \n",
    "    # First component of main path\n",
    "    input_tensor = tf.keras.layers.Conv2D(\n",
    "        filters=F1, \n",
    "        kernel_size=(1, 1), \n",
    "        strides=(1,1), \n",
    "        padding='valid', \n",
    "        name=conv_name_base + '2a', \n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(\n",
    "        axis=3, \n",
    "        name=bn_name_base + '2a')(input_tensor)\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)\n",
    "    \n",
    "    # Second component of main path\n",
    "    input_tensor=tf.keras.layers.Conv2D(\n",
    "        filters=F2, \n",
    "        kernel_size=kernel_size, \n",
    "        strides=(1,1), \n",
    "        padding='same', \n",
    "        name=conv_name_base + '2b', \n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(\n",
    "        axis=3, \n",
    "        name=bn_name_base + '2b')(input_tensor)\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    input_tensor = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=(1, 1), \n",
    "        strides=(1,1), \n",
    "        padding='valid', \n",
    "        name=conv_name_base + '2c', \n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(input_tensor)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    input_tensor = tf.keras.layers.Add()([input_tensor, input_tensor_shortcut])\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)  \n",
    "    \n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056e458-bb3e-42ee-95d4-2a8be75ac21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(\n",
    "    input_tensor, \n",
    "    kernel_size, \n",
    "    filters, \n",
    "    stage, \n",
    "    block, \n",
    "    strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "        strides: Strides for the first conv layer in the block.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    input_tensor_shortcut = input_tensor\n",
    "\n",
    "\n",
    "    # First component of main path \n",
    "    input_tensor = tf.keras.layers.Conv2D(\n",
    "        F1, \n",
    "        (1, 1), \n",
    "        strides = strides, \n",
    "        name = conv_name_base + '2a', \n",
    "        kernel_initializer = tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(\n",
    "        axis = 3, \n",
    "        name = bn_name_base + '2a')(input_tensor)\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)\n",
    "\n",
    "    input_tensor = tf.keras.layers.Conv2D(\n",
    "        filters = F2, \n",
    "        kernel_size = kernel_size, \n",
    "        strides = (1,1), \n",
    "        padding = 'same', \n",
    "        name = conv_name_base + '2b', \n",
    "        kernel_initializer = tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(\n",
    "        axis = 3, \n",
    "        name = bn_name_base + '2b')(input_tensor)\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)\n",
    "\n",
    "    input_tensor = tf.keras.layers.Conv2D(\n",
    "        filters = F3, \n",
    "        kernel_size = (1, 1), \n",
    "        strides = (1,1), \n",
    "        padding = 'valid', \n",
    "        name = conv_name_base + '2c', \n",
    "        kernel_initializer = tf.keras.initializers.GlorotUniform(seed=0))(input_tensor)\n",
    "    input_tensor = tf.keras.layers.BatchNormalization(axis = 3, name = bn_name_base + '2c')(input_tensor)\n",
    "\n",
    "    input_tensor_shortcut = tf.keras.layers.Conv2D(\n",
    "        filters = F3, \n",
    "        kernel_size = (1, 1), \n",
    "        strides = strides, \n",
    "        padding = 'valid', \n",
    "        name = conv_name_base + '1',\n",
    "        kernel_initializer = tf.keras.initializers.GlorotUniform(seed=0))(input_tensor_shortcut)\n",
    "    input_tensor_shortcut = tf.keras.layers.BatchNormalization(\n",
    "        axis = 3, \n",
    "        name = bn_name_base + '1')(input_tensor_shortcut)\n",
    "    \n",
    "    input_tensor = tf.keras.layers.Add()([input_tensor, input_tensor_shortcut])\n",
    "    input_tensor = tf.keras.layers.Activation('relu')(input_tensor)\n",
    "        \n",
    "    return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd9f48-a6f9-40cd-b60d-911fff167a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(32, 32, 10), classes=17):\n",
    "    # Define the input of the model\n",
    "    M_input = tf.keras.layers.Input(input_shape)\n",
    "    print(\"Input shape\", M_input.shape)\n",
    "\n",
    "    # Add zero padding to the patch\n",
    "    M = tf.keras.layers.ZeroPadding2D(padding=(3, 3))(M_input)\n",
    "    # Stage 1\n",
    "    M = tf.keras.layers.Conv2D(\n",
    "        filters=64, \n",
    "        kernel_size=(7, 7), \n",
    "        strides=(2, 2), \n",
    "        name='conv1', \n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(M)\n",
    "    M = tf.keras.layers.BatchNormalization(\n",
    "        axis=3, \n",
    "        name='bn_conv1')(M)\n",
    "    M = tf.keras.layers.Activation('relu')(M)\n",
    "    M = tf.keras.layers.MaxPool2D(\n",
    "        pool_size=(3, 3), \n",
    "        strides=(2, 2))(M)\n",
    "    print(\"Stage 1 shape\", M.shape)\n",
    "\n",
    "    # Stage 2\n",
    "    M = convolutional_block(\n",
    "        M, \n",
    "        kernel_size=3, \n",
    "        filters=[32, 32, 256], \n",
    "        stage=2, \n",
    "        block='a', \n",
    "        strides=(1, 1))\n",
    "    M = identity_block(M, 3, [64, 64, 256], stage=2, block='b')\n",
    "    M = identity_block(M, 3, [64, 64, 256], stage=2, block='c')\n",
    "    print(\"Stage 2 shape\", M.shape)\n",
    "\n",
    "    # Stage 3\n",
    "    M = convolutional_block(\n",
    "        M, \n",
    "        kernel_size=3, \n",
    "        filters=[128, 128, 512], \n",
    "        stage = 3, \n",
    "        block='a', \n",
    "        strides=(1, 1))\n",
    "    M = identity_block(M, 3, [128, 128, 512], stage=3, block='b')\n",
    "    M = identity_block(M, 3, [128, 128, 512], stage=3, block='c')\n",
    "    M = identity_block(M, 3, [128, 128, 512], stage=3, block='d')\n",
    "    print(\"Stage 3 shape\", M.shape)\n",
    "    \n",
    "    # Stage 4\n",
    "    M = convolutional_block(\n",
    "        M, \n",
    "        kernel_size=3, \n",
    "        filters=[256, 256, 1024], \n",
    "        stage = 4, \n",
    "        block='a', \n",
    "        strides=(2, 2))\n",
    "    M = identity_block(M, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    M = identity_block(M, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    M = identity_block(M, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    M = identity_block(M, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    M = identity_block(M, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    print(\"Stage 4 shape\", M.shape)\n",
    "\n",
    "    # Stage 5\n",
    "    M = convolutional_block(\n",
    "        M, \n",
    "        kernel_size=3, \n",
    "        filters=[512, 512, 2048], \n",
    "        stage = 5, \n",
    "        block='a', \n",
    "        strides=(2, 2))\n",
    "    M = identity_block(M, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    M = identity_block(M, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    print(\"Stage 5 shape\", M.shape)\n",
    "\n",
    "    # AVGPOOL\n",
    "    M = tf.keras.layers.AveragePooling2D((2,2), name=\"avg_pool\")(M)\n",
    "    print(\"Avg pool shape\", M.shape)\n",
    "    \n",
    "    # output layer\n",
    "    M = tf.keras.layers.Flatten()(M)\n",
    "    M = tf.keras.layers.Dense(\n",
    "        classes, \n",
    "        activation='softmax', \n",
    "        name='fc' + str(classes), \n",
    "        kernel_initializer = tf.keras.initializers.GlorotUniform)(M)\n",
    "    print(\"Output shape\", M.shape)\n",
    "    \n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs = M_input, outputs = M, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c8456-a5a0-4ed6-97b8-fcd90ff11f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn = ResNet50()\n",
    "\n",
    "\n",
    "model_rn.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de618a2a-5544-42e7-914d-2cc75d49e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn.fit(Z_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b9654-c7a1-403b-a5ae-571ad1dd6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn_p = model_rn.predict(Z_test)\n",
    "\n",
    "y_pred_rn = np.argmax(y_pred_rn_p, axis=1)\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rn)\n",
    "plt.show()\n",
    "\n",
    "acc_rn = accuracy_score(y_test, y_pred_rn)\n",
    "print(\"Accuracy ResNet-50 model: \", acc_rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345fa52c-5993-4f49-ac6a-a34da00c57b6",
   "metadata": {},
   "source": [
    "## 4. Open Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389caf14-c13f-483c-af06-efb333934398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
